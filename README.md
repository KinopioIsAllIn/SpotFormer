# SpotFormer
Official Pytorch Implementation of 'SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting'

We will release the entire code after the paper has been accepted.

Now we release the motion feature and the model of SpoT-GCN

Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting. FG 2024, Oral.

The optical flow feature of the SAMM dataset can be downloaded from [baidunetdisk](https://pan.baidu.com/s/1GbAgqFqI8ReXd23cV4Tvpw?pwd=24ys).

We implement our source code based on [USTC_ME_Spotting](https://github.com/wenhaocold/USTC_ME_Spotting).

```
@inproceedings{deng2024multi,
  title={Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting},
  author={Deng, Yicheng and Hayashi, Hideaki and Nagahara, Hajime},
  booktitle={2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)},
  pages={1--10},
  year={2024},
  organization={IEEE}
}
@article{deng2024spotformer,
  title={SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting},
  author={Deng, Yicheng and Hayashi, Hideaki and Nagahara, Hajime},
  journal={arXiv preprint arXiv:2407.20799},
  year={2024}
}
```
