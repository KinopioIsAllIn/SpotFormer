# SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting

## Introduction
Official Pytorch Implementation of 'SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting' [preprint](https://arxiv.org/abs/2407.20799)

We will release the entire code after the paper has been accepted.

Now we release the motion feature and the model of the conference version SpoT-GCN. (FG 2024, Oral.) [IEEE version](https://ieeexplore.ieee.org/abstract/document/10581968), [preprint](https://arxiv.org/abs/2403.15994).

The optical flow feature of the SAMM dataset can be downloaded from [baidunetdisk](https://pan.baidu.com/s/1GbAgqFqI8ReXd23cV4Tvpw?pwd=24ys).

## Citation
If you find our research useful, please consider citing:

```
@inproceedings{deng2024multi,
  title={Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting},
  author={Deng, Yicheng and Hayashi, Hideaki and Nagahara, Hajime},
  booktitle={2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)},
  pages={1--10},
  year={2024},
  organization={IEEE}
}
@article{deng2024spotformer,
  title={SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial Expression Spotting},
  author={Deng, Yicheng and Hayashi, Hideaki and Nagahara, Hajime},
  journal={arXiv preprint arXiv:2407.20799},
  year={2024}
}
```

## Acknowlegment
We implement our source code based on [USTC_ME_Spotting](https://github.com/wenhaocold/USTC_ME_Spotting).
